{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sourcing SCOTUS from Harvard's [Caselaw Access Project (CAP)](https://case.law/)\n",
    "\n",
    "Goal: retrieve all opinions written by the Supreme Court for a specified year range.\n",
    "\n",
    "SCOTUS denies thousands of cases every year, and each denial gets its own document, so we can't just grab all SCOTUS documents from CAP for a specified year. We need docket numbers for the cases that granted cert and argued before the court. Here, we source those docket numbers from the [Super-SCOTUS dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/POWQIT) [[paper](https://aclanthology.org/2023.nllp-1.20/)].\n",
    "\n",
    "1. Get docket numbers for the years 1986-2019 from superscotus.\n",
    "2. For each year, request a small sample (~15) cases from CAP. (waiting on unmetered API access before pulling full set)\n",
    "\n",
    "\n",
    "There also seem to be two maps from SCDB to CAP:\n",
    "1. [Connecting U.S. Supreme Court Case Information and Opinion Authorship (SCDB) to Full Case Text Data (CAP), 1791-2011](https://zenodo.org/records/4344917).\n",
    "1. CAP's own [matchup file](https://case.law/download/scdb/scdb_matchup_2020-01-16.csv) on this [page](https://case.law/download/scdb/).\n",
    "\n",
    "The maps from SCDB end in 2011. From 2007 onward, the SCOTUS website has documents with docket numbers for cases granted argument. These are the **Granted \\& Noted** [lists](https://www.supremecourt.gov/orders/grantednotedlists.aspx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Scriptify this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sqlite3\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "import aiohttp\n",
    "import jsonlines\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from scotus_metalang.diachronic_analysis import cap\n",
    "\n",
    "load_dotenv()\n",
    "CAP_TOKEN = os.environ[\"CAP_TOKEN\"]\n",
    "\n",
    "docket_nums_by_year = defaultdict(list)\n",
    "with jsonlines.open(\"data/super_scotus/1986_to_2019.jsonl\", \"r\") as f:\n",
    "    for case in f:\n",
    "        # Example case id: \"1986_84-2022\"\n",
    "        year = case[\"year\"]\n",
    "        docket_number = case[\"id\"][5:]\n",
    "        docket_nums_by_year[year].append(docket_number)\n",
    "\n",
    "docket_numbers = list(chain(*docket_nums_by_year.values()))\n",
    "docket_numbers = [{\"docket_number\": x} for x in docket_numbers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2853"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = sqlite3.connect(\"api_log.db\")\n",
    "# Insert all docket numbers into cases\n",
    "with connection:\n",
    "    connection.executemany(\"\"\"--sql\n",
    "                           INSERT OR IGNORE INTO cases (docket_number)\n",
    "                           VALUES(:docket_number)\n",
    "                           \"\"\", docket_numbers)\n",
    "# Figure out which docket numbers need to be processed\n",
    "with connection:\n",
    "    rows = connection.execute(\"\"\"--sql\n",
    "                              SELECT * FROM cases\n",
    "                              WHERE case_status != 'success' OR case_status IS NULL\n",
    "                              \"\"\").fetchall()\n",
    "docket_numbers_to_process = [row[0] for row in rows]\n",
    "\n",
    "len(docket_numbers_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    connector = aiohttp.TCPConnector(limit_per_host=10)\n",
    "    headers={\"Authorization\": f\"Token {CAP_TOKEN}\"}\n",
    "    async with aiohttp.ClientSession(connector=connector, headers=headers) as session:\n",
    "        for i, docket_number in enumerate(docket_numbers_to_process):  # Sample here to limit API usage while tinkering\n",
    "            db_params, opinions_as_params = await cap.process_opinions_by_docket_number(docket_number, session)\n",
    "            with connection:\n",
    "                connection.execute(\"\"\"--sql\n",
    "                                   UPDATE cases\n",
    "                                   SET case_status = :case_status,\n",
    "                                   selected_case_id = :selected_case_id,\n",
    "                                   decision_date = :decision_date\n",
    "                                   WHERE docket_number = :docket_number\n",
    "                                   \"\"\", db_params)\n",
    "                connection.executemany(\"\"\"--sql\n",
    "                                       INSERT INTO opinions\n",
    "                                       VALUES(:docket_number, :opinion_number, :cap_author, :author)\n",
    "                                       \"\"\", opinions_as_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docket numbers to exclude on potential rerun\n",
    "with connection:\n",
    "    rows = connection.execute(\"\"\"--sql\n",
    "                             SELECT docket_number\n",
    "                             FROM opinions\n",
    "                             GROUP BY docket_number\n",
    "                             HAVING cap_author is not null\n",
    "                             \"\"\").fetchall()\n",
    "\n",
    "docket_numbers_to_exclude = [row[0] for row in rows]\n",
    "docket_numbers_to_exclude\n",
    "\n",
    "docket_nums = list(set(docket_numbers_to_process) - set(docket_numbers_to_exclude))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scotus-metalang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
