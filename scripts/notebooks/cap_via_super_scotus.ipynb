{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sourcing SCOTUS from Harvard's [Caselaw Access Project (CAP)](https://case.law/)\n",
    "\n",
    "Goal: retrieve all opinions written by the Supreme Court for a specified year range.\n",
    "\n",
    "SCOTUS denies thousands of cases every year, so we can't just grab all SCOTUS documents from CAP for a specified year. We need docket numbers for the cases that granted cert and argued before the court. Here, we source those docket numbers from the [Super-SCOTUS dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/POWQIT) [[paper](https://aclanthology.org/2023.nllp-1.20/)].\n",
    "\n",
    "1. Get docket numbers for the years 1986-2019 from superscotus.\n",
    "2. For each year, request a small sample (~15) cases from CAP. (waiting on unmetered API access before pulling full set)\n",
    "\n",
    "**Case issues**\n",
    "- [Board of Education v. Tom F.](https://cite.case.law/us/552/1/) Here, there was a recusal, and the court split 4-4, leading to a ~2-sentence per curiam opinion saying the lower court was affirmed by default. For some reason, you can't search for this case by docket number (via web or API)\n",
    "- [Altantic Sounding Co. v. Townsend](https://cite.case.law/us/557/404/): Classified as 11th circuit instead of SCOTUS, so 9009 court filter returns 0 results with this case's docket number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ../..\n",
    "\n",
    "import jsonlines\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docket_nums_by_year = defaultdict(list)\n",
    "with jsonlines.open(\"data/super_scotus/1986_to_2019.jsonl\", \"r\") as f:\n",
    "    for case in f:\n",
    "        # Example case id: \"1986_84-2022\"\n",
    "        year = case[\"year\"]\n",
    "        docket_number = case[\"id\"][5:]\n",
    "        docket_nums_by_year[year].append(docket_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourteen_from_each = []\n",
    "for year in range(1986,2020):\n",
    "    fourteen_from_each += docket_nums_by_year[str(year)][:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP_TOKEN = os.environ[\"CAP_TOKEN\"]\n",
    "def case_json_by_id(case_id):\n",
    "    return requests.get(f\"https://api.case.law/v1/cases/{case_id}?full_case=true\",headers={\"Authorization\": f\"Token {CAP_TOKEN}\"}).json()\n",
    "\n",
    "def case_by_docket_number(docket_number):\n",
    "    return requests.get(f\"https://api.case.law/v1/cases?court_id=9009&docket_number={docket_number}\", headers={\"Authorization\": f\"Token {CAP_TOKEN}\"}).json()\n",
    "\n",
    "def longest_casebody_in_results(json_response):\n",
    "    max_word_count = 0\n",
    "    case_id_to_return = \"\"\n",
    "    for case in json_response[\"results\"]:\n",
    "        word_count = case[\"analysis\"][\"word_count\"]\n",
    "        if word_count > max_word_count:\n",
    "            max_word_count = word_count\n",
    "            case_id_to_return = case[\"id\"]\n",
    "    return case_id_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = []\n",
    "data_report = []\n",
    "for docket_number in fourteen_from_each:\n",
    "    api_response = case_by_docket_number(docket_number)\n",
    "    num_results = api_response[\"count\"]\n",
    "    if num_results == 0:\n",
    "        # TODO: Error handling\n",
    "        pass\n",
    "    else:\n",
    "        # Make note of the count and which doc we ended up choosing\n",
    "        case_id = longest_casebody_in_results(api_response)\n",
    "        case_json = case_json_by_id(case_id)\n",
    "        # TODO: Decide if the whole json is necessary to save or if we can just get the opinions\n",
    "        # TODO: Count number of opinions and add\n",
    "        cases.append(case_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"data/harvard_cap/14_cases_from_1986_to_2019.jsonl\"\n",
    "with jsonlines.open(target, \"w\") as f:\n",
    "    f.write_all(cases)\n",
    "    print(f\"{len(cases)} written to {target}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scotus-metalang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
