{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sourcing SCOTUS from Harvard's [Caselaw Access Project (CAP)](https://case.law/)\n",
    "\n",
    "Goal: retrieve all opinions written by the Supreme Court for a specified year range.\n",
    "\n",
    "SCOTUS denies thousands of cases every year, and each denial gets its own document, so we can't just grab all SCOTUS documents from CAP for a specified year. We need docket numbers for the cases that granted cert and argued before the court. Here, we source those docket numbers from the [Super-SCOTUS dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/POWQIT) [[paper](https://aclanthology.org/2023.nllp-1.20/)].\n",
    "\n",
    "1. Get docket numbers for the years 1986-2019 from superscotus.\n",
    "2. For each year, request a small sample (~15) cases from CAP. (waiting on unmetered API access before pulling full set)\n",
    "\n",
    "**Case issues**\n",
    "- [Board of Education v. Tom F.](https://cite.case.law/us/552/1/) Here, there was a recusal, and the court split 4-4, leading to a ~2-sentence per curiam opinion saying the lower court was affirmed by default. For some reason, you can't search for this case by docket number (via web or API)\n",
    "- [Altantic Sounding Co. v. Townsend](https://cite.case.law/us/557/404/): Classified as 11th circuit instead of SCOTUS, so 9009 court filter returns 0 results with this case's docket number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ../..\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import jsonlines\n",
    "\n",
    "from scotus_metalang import cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docket_nums_by_year = defaultdict(list)\n",
    "with jsonlines.open(\"data/super_scotus/1986_to_2019.jsonl\", \"r\") as f:\n",
    "    for case in f:\n",
    "        # Example case id: \"1986_84-2022\"\n",
    "        year = case[\"year\"]\n",
    "        docket_number = case[\"id\"][5:]\n",
    "        docket_nums_by_year[year].append(docket_number)\n",
    "fourteen_from_each = []\n",
    "for year in range(1986,2020):\n",
    "    fourteen_from_each += docket_nums_by_year[year][:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = Path(\"data/logs\")\n",
    "Path.mkdir(log_dir, exist_ok=True, parents=True)\n",
    "log_path = Path(log_dir, \"cap_scraping_log.tsv\")\n",
    "log_exists = os.path.exists(log_path)\n",
    "\n",
    "with open(log_path, \"r+\") as f:\n",
    "    header = [\"docket_number\", \"status\", \"cases_returned\", \"case_id_selected\", \"num_opinions\", \"authors\"]\n",
    "    reader = csv.DictReader(f, header, delimiter=\"\\t\")\n",
    "    # Add each TSV row to a dict indexed by docket number\n",
    "    log = {}\n",
    "    for line in reader:\n",
    "        docket_number = int(line.pop(\"docket_number\"))\n",
    "        log[docket_number] = line\n",
    "    log_writer = csv.DictWriter(f, header, delimiter=\"\\t\")\n",
    "    if not log_exists:\n",
    "        log_writer.writeheader()\n",
    "    for docket_number in fourteen_from_each[:5]:  # Sample here to limit API usage while tinkering\n",
    "        cap.save_opinions_by_docket_number(docket_number, log, log_writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scotus-metalang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
